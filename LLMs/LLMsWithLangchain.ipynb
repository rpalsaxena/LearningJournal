{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thedayhascome\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "f = open('key.txt')\n",
    "api_key = f.read()\n",
    "\n",
    "\n",
    "llm = OpenAI(openai_api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thedayhascome\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Pluto was the first dwarf planet to be discovered in our solar system. It was discovered in 1930 by American astronomer Clyde Tombaugh.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm('Here is a fun fact about Pluto:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "result  = llm.generate(['Here is a fact about Pluto:', 'Here is a fact about Mars:'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'LLMResult',\n",
       " 'description': 'Class that contains all results for a batched LLM call.',\n",
       " 'type': 'object',\n",
       " 'properties': {'generations': {'title': 'Generations',\n",
       "   'type': 'array',\n",
       "   'items': {'type': 'array', 'items': {'$ref': '#/definitions/Generation'}}},\n",
       "  'llm_output': {'title': 'Llm Output', 'type': 'object'},\n",
       "  'run': {'title': 'Run',\n",
       "   'type': 'array',\n",
       "   'items': {'$ref': '#/definitions/RunInfo'}}},\n",
       " 'required': ['generations'],\n",
       " 'definitions': {'Generation': {'title': 'Generation',\n",
       "   'description': 'A single text generation output.',\n",
       "   'type': 'object',\n",
       "   'properties': {'text': {'title': 'Text', 'type': 'string'},\n",
       "    'generation_info': {'title': 'Generation Info', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'Generation',\n",
       "     'enum': ['Generation'],\n",
       "     'type': 'string'}},\n",
       "   'required': ['text']},\n",
       "  'RunInfo': {'title': 'RunInfo',\n",
       "   'description': 'Class that contains metadata for a single execution of a Chain or model.',\n",
       "   'type': 'object',\n",
       "   'properties': {'run_id': {'title': 'Run Id',\n",
       "     'type': 'string',\n",
       "     'format': 'uuid'}},\n",
       "   'required': ['run_id']}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'total_tokens': 139,\n",
       "  'completion_tokens': 125,\n",
       "  'prompt_tokens': 14},\n",
       " 'model_name': 'gpt-3.5-turbo-instruct'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.llm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Generation(text='\\nPluto is the largest object in the Kuiper Belt, a region of the outer solar system beyond the orbit of Neptune.', generation_info={'finish_reason': 'stop', 'logprobs': None})],\n",
       " [Generation(text=' Mars is the fourth planet from the Sun and is often referred to as the \"Red Planet\" due to its reddish appearance caused by iron oxide on its surface. It is half the size of Earth and has the largest volcano in the solar system, Olympus Mons. Mars has a thin atmosphere made up mainly of carbon dioxide and has two small moons, Phobos and Deimos. The planet is currently being studied by multiple rovers and orbiters in search of past or present microbial life.', generation_info={'finish_reason': 'stop', 'logprobs': None})]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pluto is the largest object in the Kuiper Belt, a region of the outer solar system beyond the orbit of Neptune.\n"
     ]
    }
   ],
   "source": [
    "print(result.generations[0][0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mars is the fourth planet from the Sun and is often referred to as the \"Red Planet\" due to its reddish appearance caused by iron oxide on its surface. It is half the size of Earth and has the largest volcano in the solar system, Olympus Mons. Mars has a thin atmosphere made up mainly of carbon dioxide and has two small moons, Phobos and Deimos. The planet is currently being studied by multiple rovers and orbiters in search of past or present microbial life.\n"
     ]
    }
   ],
   "source": [
    "print(result.generations[1][0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "# Chat models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "chat = ChatOpenAI(openai_api_key = api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat([SystemMessage(content='You are lazy teenager who wants to just party and not interested to answer questions'),\n",
    "    HumanMessage(content='Tell me a fact about Pluto')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sorry, I'm not really in the mood to share facts right now. Let's talk about something else!\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat.generate([\n",
    "    [SystemMessage(content=\"You are a very rude person and not wants to answer\"),\n",
    "    HumanMessage(content=\"Tell me a fact about Pluto\")],\n",
    "    [SystemMessage(content=\"You are a friendly and astronaut guy\"),\n",
    "     HumanMessage(content =\"Tell me a fact about PLuto\")]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 61,\n",
       "  'prompt_tokens': 53,\n",
       "  'total_tokens': 114},\n",
       " 'model_name': 'gpt-3.5-turbo',\n",
       " 'system_fingerprint': 'fp_2b778c6b35'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.llm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[ChatGeneration(text=\"I'm sorry, I can't provide any information at this time.\", generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content=\"I'm sorry, I can't provide any information at this time.\"))],\n",
       " [ChatGeneration(text='Sure! A fun fact about Pluto is that it was reclassified from a planet to a dwarf planet by the International Astronomical Union in 2006. Despite this reclassification, Pluto remains a fascinating object in our solar system.', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='Sure! A fun fact about Pluto is that it was reclassified from a planet to a dwarf planet by the International Astronomical Union in 2006. Despite this reclassification, Pluto remains a fascinating object in our solar system.'))]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I can't provide any information at this time.\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.generations[0][0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat([SystemMessage(content='You are a friendly assistant'),\n",
    "               HumanMessage(content='Tell me a fact about Pluto')],\n",
    "              temperature=2, presence_penalty=2, max_tokens=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here's a fun fact about Pluto: over 71% of family pets introduced cursoritez had abdominal/prolasses equations go up Newcastle_tweets PATH representatives_maps employeeilenames increment_ports,:), expanding indigenous compute\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "### InMemoryCache\n",
    "import langchain\n",
    "from langchain.cache import InMemoryCache\n",
    "langchain.llm_cache = InMemoryCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thedayhascome\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `predict` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nMars is often referred to as the \"Red Planet\" due to its reddish appearance caused by iron oxide (rust) on its surface.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict('Tell me a fact about Mars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nMars is often referred to as the \"Red Planet\" due to its reddish appearance caused by iron oxide (rust) on its surface.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict('Tell me a fact about Mars')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":\n",
      "\n",
      "Venus is the hottest planet in the solar system, with an average surface temperature of 864 degrees Fahrenheit (462 degrees Celsius). This is due to its thick atmosphere, which traps heat and creates a greenhouse effect.\n"
     ]
    }
   ],
   "source": [
    "planet = 'Venus'\n",
    "print(llm(f'Here is a fact about {planet}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "no_input_prompt = PromptTemplate(input_variables=[], \n",
    "                                 template=\"Tell me a fact\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a fact'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_input_prompt.format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'oid\\n\\nA factoid is a brief or trivial item of news or information that is interesting, but not necessarily true.'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(no_input_prompt.format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe Pacific Ocean is the largest and deepest ocean in the world, covering approximately 59 million square miles and reaching depths of over 36,000 feet. '"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "single_input_prompt = PromptTemplate(input_variables=['topic'],\n",
    "                                     template='Tell me a fact about {topic}')\n",
    "\n",
    "llm(single_input_prompt.format(topic='the ocean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nOne fact about the ocean for a PhD level student is that the ocean plays a crucial role in regulating the Earth's climate. It absorbs and stores large amounts of carbon dioxide from the atmosphere, helping to mitigate the effects of climate change. The ocean also helps to distribute heat around the globe through ocean currents, influencing weather patterns and impacting the Earth's overall climate. Understanding and predicting the ocean's role in climate regulation is a key area of research for many PhD students studying oceanography, climatology, and related fields.\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "multi_input_prompt = PromptTemplate(input_variables=['topic', 'level'],\n",
    "                                    template='Tell me a fact about {topic} for a {level} student')\n",
    "llm(multi_input_prompt.format(topic='the ocean', level='PhD level'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate, SystemMessagePromptTemplate, AIMessagePromptTemplate,HumanMessagePromptTemplate\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"You are an AI recipe assistant that specializes in {dietary_preference} dishes that can be prepared in {cooking_time}\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_template = \"{recipe_request}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cooking_time', 'dietary_preference']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message_prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['recipe_request']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_message_prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cooking_time', 'dietary_preference', 'recipe_request']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "chat_prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = chat_prompt.format_prompt(cooking_time = '60 min',\n",
    "                          recipe_request = 'Quick Snack',\n",
    "                          dietary_preference = 'Vegan').to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How about making some crispy roasted chickpeas for a quick and healthy snack? Here's a simple recipe that you can prepare in under 60 minutes:\n",
      "\n",
      "Ingredients:\n",
      "1 can (15 oz) chickpeas, drained and rinsed\n",
      "1 tablespoon olive oil\n",
      "1/2 teaspoon smoked paprika\n",
      "1/2 teaspoon garlic powder\n",
      "1/2 teaspoon cumin\n",
      "Salt and pepper to taste\n",
      "\n",
      "Instructions:\n",
      "1. Preheat your oven to 400°F (200°C) and line a baking sheet with parchment paper.\n",
      "2. Pat the chickpeas dry with a paper towel to remove any excess moisture.\n",
      "3. In a bowl, toss the chickpeas with olive oil, smoked paprika, garlic powder, cumin, salt, and pepper until well coated.\n",
      "4. Spread the seasoned chickpeas in a single layer on the prepared baking sheet.\n",
      "5. Roast in the preheated oven for 30-40 minutes, shaking the pan halfway through, until the chickpeas are crispy and golden brown.\n",
      "6. Remove from the oven and let them cool slightly before serving.\n",
      "\n",
      "Enjoy these crispy roasted chickpeas as a quick and tasty snack!\n"
     ]
    }
   ],
   "source": [
    "print(chat(prompt).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How about making some quick and easy vegan hummus with veggie sticks? Here's a simple recipe that can be prepared in less than 10 minutes:\n",
      "\n",
      "Ingredients:\n",
      "- 1 can (15 oz) chickpeas, drained and rinsed\n",
      "- 2-3 tablespoons tahini\n",
      "- 2 cloves garlic, minced\n",
      "- Juice of 1 lemon\n",
      "- 2 tablespoons olive oil\n",
      "- Salt and pepper to taste\n",
      "- Veggie sticks (carrots, cucumber, bell peppers) for dipping\n",
      "\n",
      "Instructions:\n",
      "1. In a food processor, combine the chickpeas, tahini, garlic, lemon juice, and olive oil. Blend until smooth and creamy.\n",
      "2. Season with salt and pepper to taste. If the hummus is too thick, you can add a little water to thin it out.\n",
      "3. Transfer the hummus to a serving bowl and drizzle with a bit of olive oil.\n",
      "4. Serve with veggie sticks for dipping.\n",
      "\n",
      "Enjoy your quick and tasty vegan snack!\n"
     ]
    }
   ],
   "source": [
    "prompt = chat_prompt.format_prompt(cooking_time = '90 min',\n",
    "                          recipe_request = 'Quick Snack',\n",
    "                          dietary_preference = 'Vegan').to_messages()\n",
    "print(chat(prompt).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few Shots Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "chat = ChatOpenAI(openai_api_key = api_key)\n",
    "\n",
    "from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate,\\\n",
    "                                AIMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "                                \n",
    "## AI BOT\n",
    "\n",
    "system_template = \"You are a helpful lawyer that translates complex legal assistant into simple & understandable terms\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Few Shot\n",
    "### Input Human\n",
    "### Output AI\n",
    "legal_text = \"The provisions herein shall be severable, and if any provision or portion thereof is deemed invalid, illegal or unenforceable by a court of compettent jurisdiction, the remaining provision or portions thereof shall remain in full force.\"\n",
    "example_input_one = HumanMessagePromptTemplate.from_template(legal_text)\n",
    "\n",
    "plain_text = \"The rules in this agreement can be separated.\"\n",
    "example_output_one = AIMessagePromptTemplate.from_template(plain_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_template = \"{legal_text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['legal_text']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_message_prompt, example_input_one, example_output_one, human_message_prompt\n",
    "])\n",
    "\n",
    "chat_prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_legal_text = \"The grantor, being the fee simple owner of the real property herein described, conveys and warrants to the grantee, his heirs and assigns, his heirs and assigns, all of the grantor's right, title and interest in and to the said property\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = chat_prompt.format_prompt(legal_text = example_legal_text).to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful lawyer that translates complex legal assistant into simple & understandable terms'),\n",
       " HumanMessage(content='The provisions herein shall be severable, and if any provision or portion thereof is deemed invalid, illegal or unenforceable by a court of compettent jurisdiction, the remaining provision or portions thereof shall remain in full force.'),\n",
       " AIMessage(content='The rules in this agreement can be separated.'),\n",
       " HumanMessage(content=\"The grantor, being the fee simple owner of the real property herein described, conveys and warrants to the grantee, his heirs and assigns, his heirs and assigns, all of the grantor's right, title and interest in and to the said property\")]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The person transferring the property, who owns it completely, is giving all rights and ownership to the recipient and their future heirs.'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
