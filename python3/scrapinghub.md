# Mission ScrapingHub

I have started working on this project by the end of 2019. 
ScrapingHub's vision is in alignment with my goals. 
I have used their framework(scrapy) in past so have some bonding with it.
Every developer wants to get involved in Opensource stuff but due to job or technical issues they don't get time to work on it.
Now, I have good enough skillset to contribute in Opensource world. 
I have had chance to work with some researchers(college profs) to help them implement there tasks.
I also completed freelancing projects otherthan that I have taught 1000s of students via Udacity. 
All this helped me to grow and be better. But still there's a lot more that I have to do.
I believe that I was able to achieve all this as I was working as per my way. 
I managed my time, my goals and achieved the results.

Scrapinghub is an organization which is actually working like an interface to connect developers.
There scrapy framework is an awesome one to aggregate data. 
While working in data science domain, I saw that data gathering is one such thing that's not discussed in detail.

Am trying to build a strategy to join this organization. Although I want to create a pull request from them.
For this, I will have to upskill myself and make me better. If I will be the owner of that org, I want devs who need not 
to be trained. They can start working with the team in a week.

- I spent the last fortnight to understand price-parser library. It's coded in
a pretty well manner. I invested time to understand `Optional`, `Decimal`, `Callable` etc.
I have worked on an issue and created a pull request. Currently am waiting for their response.

Am eligible for Data Scientist position but as they are currently looking for the 
python developers. So, I will be focusing for that position. 
 
 
 
------
 
 In the below section, I'll be grabbing keywords from their JD that can be 
 beneficial for me to prep for the job:
 
 - *Delivery team* for crawler development with *Scrapy*
- *strong open source foundation*
- should be aware of scrapinghub's projects. Can do the distributed crawling over cloud.
*performance, scalability, distributed, debugging, fixing of issues*

They have projects, if you are good then you can help get them more business.

- solid Python3 knowledge
- Familiarity with Linux/UNIX, HTTP, HTML, Javascript and Networking.

--------